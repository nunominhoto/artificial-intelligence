{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/K5IH3Ut.jpg\" align=\"left\" alt=\"Kitten\" title=\"feup_logo\" width=\"100\" height=\"100\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #                                 FEUP - MIEIC - IART 2020/2021 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de \"Reinforcement Learning\" ao jogo \"10Pair\" \n",
    "\n",
    "Jogo original de onde foi adaptado: [10Pair](https://www.logicgamesonline.com/tenpair/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do ambiente:\n",
    "\n",
    "Mais simplificado do que o original.\n",
    "Tamanho do tabuleiro 4 colunas por 2 linhas.\n",
    "Sem opção de deal para aumentar mais o tabuleiro. Quando atinge um estado bloqueado o nivel dá reset.\n",
    "\n",
    "Objetivo: Eliminar os números, esvaziando o tabuleiro\n",
    "Os números são eliminados combinando-os se:\n",
    "<ul>\n",
    "<li>Forem números iguais</li>\n",
    "<li>A soma dos números é 10</li>\n",
    "<li>Adjacentes (vertical ou esquerda -> direita)</li>\n",
    "<li>Espaços vazios (0) não contam </li>\n",
    "</ul>\n",
    "\n",
    "Representação dos estados é feita pelo número decimal coorrespondente ao número binário do atual tabuleiro em que se o número na posição for diferente de 0, coorresponde a um 1 e se a posição no tabuleiro for um 0, coorresponde a um 0 no número binário.\n",
    "\n",
    "Exemplo:<br>\n",
    "[2, 3, 3, 0]<br>\n",
    "[8, 3, 7, 0]\n",
    "\n",
    "numero binário: 11101110<br>\n",
    "numero décimal: 238<br>\n",
    "\n",
    "Por cada ação possivel executada que não resulte na resolução do nivel é dada uma reward de -1.\n",
    "Se for feita uma ação que resulte na conclusão do nivel é dada uma reward de 1.\n",
    "Se uma ação resultar num estado bloqueado em que não seja possível tomar nenhuma ação, é dada uma reward de -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create our custom environment for the game\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "class game_10pair(gym.Env):\n",
    "    \n",
    " board = np.zeros(shape=(2,4))\n",
    "\n",
    " #commented levels that gave us the most trouble \n",
    " #board = np.array([[5, 5, 9, 4],[5, 4, 9, 5]])\n",
    " #board = np.array([[8, 1, 2, 1],[9, 8, 2, 1]])\n",
    " #board = np.array([[5, 9, 9, 9],[9, 1, 5, 9]])\n",
    "    \n",
    " current_state = 0\n",
    "\n",
    " usable_board = np.array(board)\n",
    "    \n",
    " def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(11)\n",
    "        self.observation_space = gym.spaces.Discrete(256)\n",
    "        \n",
    "        i=0;\n",
    "          \n",
    "        #to use one of the hard coded levels coment the next line\n",
    "        self.create_board()\n",
    "        \n",
    "        self.state = self.reset()\n",
    "        \n",
    " def reverse_Action(self, quant):\n",
    "    \n",
    "        #0(numeros iguais) 1(soma=10)\n",
    "        action = random.randint(0, 1)\n",
    "\n",
    "        n1 = random.randint(1, 9)\n",
    "        \n",
    "        if action == 0:\n",
    "            n2 = n1\n",
    "        elif action ==1:\n",
    "            n2 = 10-n1\n",
    "            \n",
    "        \n",
    "        x1 = random.randint(0, 3)\n",
    "        y1 = random.randint(0, 1)\n",
    "        \n",
    "        \n",
    "        if quant == 3:\n",
    "            f=1\n",
    "            xi=0\n",
    "            yi=0\n",
    "            \n",
    "            while 1:\n",
    "                if self.board[yi][xi] == 0:\n",
    "                    if f==1:\n",
    "                        self.board[yi][xi]=n1                 \n",
    "                        f=2\n",
    "                    elif f==2:\n",
    "                        self.board[yi][xi]=n2\n",
    "                        return 1\n",
    "                \n",
    "                xi = xi+1\n",
    "                \n",
    "                if xi > 3:\n",
    "                    xi = xi-4\n",
    "                    yi = 1\n",
    "                \n",
    "        \n",
    "        if self.board[y1][x1] == 0:\n",
    "            \n",
    "            #0(horizontal) 1(vertical)\n",
    "            d = action = random.randint(0, 1)\n",
    "           \n",
    "            if d == 0:\n",
    "                 \n",
    "                x2 = random.randint(0,7)\n",
    "                \n",
    "                if x2 > 3:\n",
    "                    x2=x2-4\n",
    "                    y2=1\n",
    "                else: \n",
    "                    y2=0\n",
    "                if self.possible(x1, y1, x2, y2) == True and (x1 != x2 and y1 != y2):\n",
    "                    \n",
    "                    if self.board[y2][x2] == 0:\n",
    "\n",
    "                        self.board[y1][x1] = n1\n",
    "                        self.board[y2][x2] = n2\n",
    "                        \n",
    "                        return 1\n",
    "                                    \n",
    "            elif d==1:\n",
    "                if y1 == 0 and self.board[y1+1][x1]==0:\n",
    "                    y2 = 1\n",
    "                    x2 = x1\n",
    "                    self.board[y1][x1] = n1\n",
    "                    self.board[y2][x2] = n2\n",
    "                    \n",
    "                    return 1\n",
    "                elif y1 == 1 and self.board[y1-1][x1]==0:\n",
    "                    y2 = 0\n",
    "                    x2 = x1\n",
    "                    self.board[y1][x1] = n1\n",
    "                    self.board[y2][x2] = n2\n",
    "                    \n",
    "                    return 1\n",
    "                \n",
    "        return 0\n",
    "    \n",
    " def create_board(self):\n",
    "        count = 0\n",
    "\n",
    "        while count < 4:\n",
    "            count = count + self.reverse_Action(count)\n",
    "\n",
    " def possible(self, x1, y1, x2, y2):\n",
    "            \n",
    "        xi=0\n",
    "        xo=0\n",
    "        yi=0\n",
    "        yo=0\n",
    "        \n",
    "        if y1<y2:\n",
    "            xi = x1+1\n",
    "            yi = y1\n",
    "            xo = x2\n",
    "            yo = y2\n",
    "        elif y2<y1:\n",
    "            xi = x2+1\n",
    "            yi = y2\n",
    "            xo = x1\n",
    "            yo = y1\n",
    "        elif y2==y1:\n",
    "            if x1<x2:\n",
    "                xi=x1+1\n",
    "                yi = y1\n",
    "                xo = x2\n",
    "                yo = yi\n",
    "            elif x2<x1:\n",
    "                xi=x2+1\n",
    "                yi = y2\n",
    "                xo = x1\n",
    "                yo = yi\n",
    "        \n",
    "        if xi > 3:\n",
    "            xi = xi-4\n",
    "            yi = 1\n",
    "        \n",
    "        while 1:\n",
    "            \n",
    "            if xi == xo and yi==yo:\n",
    "                break\n",
    "            \n",
    "            if self.board[yi][xi] != 0:\n",
    "                return False\n",
    "        \n",
    "            xi +=1\n",
    "            \n",
    "            if xi > 3 and yi == 0:\n",
    "                xi=xi-4\n",
    "                yi = 1\n",
    "        \n",
    "        return True\n",
    "      \n",
    " def step(self, action):\n",
    "        \n",
    "        #if blocked\n",
    "        if(action == 404):\n",
    "            reward = -2\n",
    "            state = self.state\n",
    "            done = True\n",
    "        else:\n",
    "            first, second = self.action_to_move(action)\n",
    "\n",
    "            self.usable_board[first[0]][first[1]]=0\n",
    "            self.usable_board[second[0]][second[1]]=0\n",
    "\n",
    "            done = self.game_ended()\n",
    "            \n",
    "            if done == True:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = -1\n",
    "\n",
    "            board_aux = np.concatenate(self.usable_board)\n",
    "\n",
    "            only1and0=[1 if i!=0 else 0 for i in board_aux]\n",
    "\n",
    "            state = 0\n",
    "\n",
    "            for i in range(len(only1and0)):\n",
    "                state += only1and0[i]*2**(7-i)\n",
    "            \n",
    "            self.state = state\n",
    "        return reward, done, state\n",
    "    \n",
    " def get_possible_action(self):\n",
    "    \n",
    "    \n",
    "    first = []\n",
    "    second = []\n",
    "    count = 0\n",
    "    while count < 100:\n",
    "        r = random.randint(0, 10)\n",
    "        \n",
    "        first, second = self.action_to_move(r)\n",
    "        \n",
    "        if(self.possible_move(first, second)):\n",
    "            return r\n",
    "        \n",
    "        first.clear()\n",
    "        second.clear()\n",
    "        \n",
    "        count = count + 1\n",
    "    \n",
    "    return 404\n",
    "                       \n",
    " def possible_move(self, one, two):\n",
    "               \n",
    "    xi = one[1]\n",
    "    yi = one[0]\n",
    "    \n",
    "    xo = two[1]\n",
    "    yo = two[0]\n",
    "    \n",
    "    if self.usable_board[yi][xi] == 0 or self.usable_board[yo][xo] == 0:\n",
    "        return False\n",
    "    \n",
    "    #same vertical\n",
    "    if(xi == xo):\n",
    "        if (self.usable_board[yi][xi] == self.usable_board[yo][xo]) or (self.usable_board[yi][xi]+self.usable_board[yo][xo] == 10):\n",
    "            #self.usable_board[yi][xi] = 0\n",
    "            #self.usable_board[yo][xo] = 0\n",
    "            if(self.usable_board[yi][xi] != 0):\n",
    "                return True\n",
    "    else:#same horizontal\n",
    "        board_aux = np.concatenate(self.usable_board)\n",
    "        \n",
    "        if yi == 1:\n",
    "            xi = xi+4\n",
    "        \n",
    "        if yo == 1:\n",
    "            xo = xo+4\n",
    "            \n",
    "        if(xi < xo):\n",
    "            i=xi+1\n",
    "            j=xo\n",
    "        elif (xo<xi):\n",
    "            i=xo+1\n",
    "            j=xi\n",
    "            \n",
    "        sum = 0\n",
    "        \n",
    "        while i != j: \n",
    "            sum = sum + board_aux[i]\n",
    "            i = i+1\n",
    "            \n",
    "        if ((board_aux[xi] == board_aux[xo]) or (board_aux[xi]+board_aux[xo] == 10)) and (sum == 0):\n",
    "            #self.usable_board[init[0]][init[1]] = 0\n",
    "            #self.usable_board[dest[0]][dest[1]] = 0\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    " def render(self):\n",
    "    print(self.usable_board)\n",
    "\n",
    " def reset(self):\n",
    "               \n",
    "        self.usable_board = deepcopy(self.board)\n",
    "        \n",
    "        state = 255\n",
    "        return state\n",
    " def game_ended(self):\n",
    "    board_aux = np.concatenate(self.usable_board)\n",
    "    \n",
    "    if sum(board_aux) != 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "     #functions that converts the action number to coordinates of numbers to remove\n",
    " def find_next(self, xi):\n",
    "        self.board_aux = np.concatenate(self.usable_board)\n",
    "\n",
    "        sol = []\n",
    "\n",
    "        x = xi+1\n",
    "        \n",
    "        while x < len(self.board_aux):\n",
    "            if self.board_aux[x] != 0:\n",
    "                if x > 3:\n",
    "                    sol.append(1)\n",
    "                    sol.append(x-4)\n",
    "                else: \n",
    "                    sol.append(0)\n",
    "                    sol.append(x)\n",
    "                    \n",
    "                return sol\n",
    "            elif x == 7:\n",
    "                sol.append(1)\n",
    "                sol.append(x-4)\n",
    "                \n",
    "                return sol\n",
    "            \n",
    "            x = x+1\n",
    "        \n",
    "\n",
    "\n",
    " def action_to_move(self, action):\n",
    "        #pair of numbers to remove\n",
    "        num1 = [] \n",
    "        num2 = []\n",
    "\n",
    "        if action == 0:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(0) #x coord\n",
    "\n",
    "            aux = self.find_next(0)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 1:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(1) #x coord\n",
    "\n",
    "            aux = self.find_next(1)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 2:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(2) #x coord\n",
    "\n",
    "            aux = self.find_next(2)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 3:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(3) #x coord\n",
    "\n",
    "            aux = self.find_next(3)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 4:\n",
    "            num1.append(1) #y coord\n",
    "            num1.append(0) #x coord\n",
    "\n",
    "            aux = self.find_next(4)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 5:\n",
    "            num1.append(1) #y coord\n",
    "            num1.append(1) #x coord\n",
    "\n",
    "            aux = self.find_next(5)\n",
    "\n",
    "            num2.append(aux[0])#y coord\n",
    "            num2.append(aux[1])#x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 6:\n",
    "            num1.append(1) #y coord\n",
    "            num1.append(2) #x coord\n",
    "\n",
    "            num2.append(1) #y coord\n",
    "            num2.append(3) #x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 7:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(0) #x coord\n",
    "\n",
    "            num2.append(1) #y coord\n",
    "            num2.append(0) #x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 8:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(1) #x coord\n",
    "\n",
    "            num2.append(1) #y coord\n",
    "            num2.append(1) #x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 9:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(2) #x coord\n",
    "\n",
    "            num2.append(1) #y coord\n",
    "            num2.append(2) #x coord\n",
    "\n",
    "            return num1, num2\n",
    "        elif action == 10:\n",
    "            num1.append(0) #y coord\n",
    "            num1.append(3) #x coord\n",
    "\n",
    "            num2.append(1) #y coord\n",
    "            num2.append(3) #x coord\n",
    "\n",
    "            return num1, num2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for Q-learning\n",
    "\n",
    "# @hyperparameters\n",
    "total_episodes = 50        # Total episodes\n",
    "learning_rate = 0.5          # Learning rate\n",
    "max_steps = 99                # Max steps per episode\n",
    "gamma = 0.95                  # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1               # Exploration rate\n",
    "max_epsilon = 1             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.001             # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current board\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action size: 11, state size: 256\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Criating the environment object\n",
    "env = game_10pair()\n",
    "\n",
    "print(\"Current board\")\n",
    "env.render()\n",
    "\n",
    "# List of rewards\n",
    "rewards = []\n",
    "\n",
    "# Create Q-table\n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "print(f'action size: {action_size}, state size: {state_size}')\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "print(qtable)\n",
    "\n",
    "done = False\n",
    "\n",
    "reward = 0\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "#env.render()\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    total_rewards = 0\n",
    "    state = 255\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    env.reset()\n",
    "    \n",
    "    for steps in range(max_steps):\n",
    "        \n",
    "        exp_exp_tradeoff = random.uniform(0, 1)\n",
    "        \n",
    "        #print(f\"exp_exp_tradeoff: {exp_exp_tradeoff}\")\n",
    "        \n",
    "        ## If this number > greater than epsilon --> exploitation \n",
    "        #(taking the biggest Q value for this state)\n",
    "        if exp_exp_tradeoff > epsilon:\n",
    "            #print('exploit')\n",
    "\n",
    "            mx_reward = -99\n",
    "            mx_index = 0\n",
    "\n",
    "            for i in range(11):\n",
    "                if qtable[state, i] != 0 and qtable[state, i] > mx_reward and env.possible_move(*env.action_to_move(i)) == True:\n",
    "                    mx_reward = qtable[state, i]\n",
    "                    mx_index = i\n",
    "\n",
    "            action = mx_index\n",
    "                # Else doing a random choice --> exploration\n",
    "        else:\n",
    "            action = env.get_possible_action()\n",
    "            \n",
    "        #print('before step')\n",
    "            \n",
    "        reward, done, new_state = env.step(action)\n",
    "        \n",
    "        \n",
    "        \n",
    "        state_actions={}\n",
    "        \n",
    "    \n",
    "        state_actions=qtable[new_state,:] \n",
    "            \n",
    "        if sum(state_actions) == 0:\n",
    "            new_state_mx_reward = 0\n",
    "        else:\n",
    "            #new_state_mx_reward = np.max(qtable[new_state, :])\n",
    "            ma = state_actions[state_actions != 0]           \n",
    "            new_state_mx_reward = ma.max()\n",
    "          \n",
    "        if action == 404:\n",
    "                qtable[state, :] = qtable[state, :] + reward\n",
    "        else:\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * new_state_mx_reward - qtable[state, action])\n",
    "        \n",
    "        total_reward = total_reward + reward\n",
    "            \n",
    "        state = new_state\n",
    "        \n",
    "        #game ended\n",
    "        if done:\n",
    "            \n",
    "            \n",
    "            break\n",
    "   \n",
    "         \n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "    rewards.append(total_rewards)\n",
    "\n",
    "#print(qtable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 2.]\n",
      " [6. 0. 8. 4.]]\n",
      "[-24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.]\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "[ 0.    0.    0.   -0.05  0.    0.    0.    0.    0.    0.    0.  ]\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -1.04750092  0.          0.        ]\n",
      "[[4. 0. 6. 2.]\n",
      " [6. 0. 8. 4.]]\n",
      "[-20.00068359   0.           0.           0.           0.\n",
      "   0.           0.          -1.04750729   0.           0.\n",
      "   0.        ]\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.         -1.99513927 -1.99514108  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Visualize learning outcome\n",
    "\n",
    "env.reset()\n",
    "\n",
    "state = []\n",
    "\n",
    "board = np.concatenate(env.usable_board)\n",
    "\n",
    "for i in range(len(qtable)):\n",
    "    state = qtable[i,:] \n",
    "    \n",
    "    if sum(state) != 0:\n",
    "      \n",
    "        bin_state = ([int(d) for d in str(bin(i))[2:].zfill(8)])\n",
    "        \n",
    "        state_board = []\n",
    "        \n",
    "        state_board=[board[j] if bin_state[j]!=0 else 0 for j in range(len(bin_state))]\n",
    "        \n",
    "        middle_index = len(state_board)//2            \n",
    "        print(np.array([state_board[:middle_index], state_board[middle_index:]]))\n",
    "        print(state) \n",
    "  \n",
    "    state = []\n",
    "\n",
    "# Print the action in every place\n",
    "#Actions from 0 to 6 do horizontal combinations \n",
    "#pick the number on the action index and combine it the first one on its right diferent from 0\n",
    "#Actions from 7 to 10 do vertical combinations\n",
    "#where 7 in the action combining the first pair of vertical numbers and 10 refers to combining the last vertical pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na Qtable apresentada em cima, apenas estão representados os estados possiveis que possam existir no nível.\n",
    "\n",
    "<ul>\n",
    "<li>Uma reward=0 para uma ação representa um movimento impossível de se concretizar.\n",
    "<li>Um estado em que todas as ações tenham rewards iguais e negativas corresponde a um estado em que o nivel está bloqueado e não é possível prosseguir com nenhum movimento, sendo necessário dar reset ao nível.\n",
    "<li>Um estado tem uma ação com uma reward positiva quando esse movimento leva á conclusão de um nível.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action to perform:  7\n",
      "possible:  True\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "action to perform:  8\n",
      "possible:  True\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "action to perform:  3\n",
      "possible:  True\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "action to perform:  2\n",
      "possible:  True\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action to perform:  7\n",
      "possible:  True\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "action to perform:  8\n",
      "possible:  True\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "action to perform:  3\n",
      "possible:  True\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "action to perform:  2\n",
      "possible:  True\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action to perform:  7\n",
      "possible:  True\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "action to perform:  8\n",
      "possible:  True\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "action to perform:  3\n",
      "possible:  True\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "action to perform:  2\n",
      "possible:  True\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action to perform:  7\n",
      "possible:  True\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "action to perform:  8\n",
      "possible:  True\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "action to perform:  3\n",
      "possible:  True\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "action to perform:  2\n",
      "possible:  True\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "[[4. 5. 6. 2.]\n",
      " [6. 5. 8. 4.]]\n",
      "action to perform:  7\n",
      "possible:  True\n",
      "[[0. 5. 6. 2.]\n",
      " [0. 5. 8. 4.]]\n",
      "action to perform:  8\n",
      "possible:  True\n",
      "[[0. 0. 6. 2.]\n",
      " [0. 0. 8. 4.]]\n",
      "action to perform:  3\n",
      "possible:  True\n",
      "[[0. 0. 6. 0.]\n",
      " [0. 0. 0. 4.]]\n",
      "action to perform:  2\n",
      "possible:  True\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Full Exploit testing!\n",
    "\n",
    "#All the episodes are the same taking the maximum of Qtable value every time\n",
    "\n",
    "for episode in range(5):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    print(\"****************************************************\")\n",
    "    print(\"EPISODE \", episode)\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        env.render()\n",
    "        \n",
    "        #print(qtable[state, :])\n",
    "        \n",
    "        mx_reward = -99\n",
    "        mx_index = 0\n",
    "        \n",
    "        for i in range(11):\n",
    "            if qtable[state, i] != 0 and qtable[state, i] > mx_reward and env.possible_move(*env.action_to_move(i)) == True:\n",
    "                mx_reward = qtable[state, i]\n",
    "                mx_index = i\n",
    "\n",
    "        action = mx_index\n",
    "        \n",
    "        print(\"action to perform: \", action)\n",
    "        \n",
    "        print(\"possible: \", env.possible_move(*env.action_to_move(action)))\n",
    "        \n",
    "        reward, done, new_state = env.step(action)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        state = new_state\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de ações\n",
    "\n",
    "<ul>\n",
    "<li>0: movimento para a direita do primeiro número da primeira linha</li>\n",
    "<li>1: movimento para a direita do segundo número da primeira linha</li>\n",
    "<li>2: movimento para a direita do terceiro número da primeira linha</li>\n",
    "<li>3: movimento para a direita do quarto número da primeira linha</li>\n",
    "<li>4: movimento para a direita do primeiro número da segunda linha</li>\n",
    "<li>5: movimento para a direita do segundo número da segunda linha</li>\n",
    "<li>6: movimento para a direita do terceiro número da segunda linha</li>\n",
    "<li>7: movimento vertical na primeira coluna</li>\n",
    "<li>8: movimento vertical na segunda coluna</li>\n",
    "<li>9: movimento vertical na terceira coluna</li>\n",
    "<li>10: movimento vertical na quarta coluna</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
